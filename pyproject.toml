[project]
name = "celestial-tts"
version = "0.13.1"
description = "A Text-to-Speech (TTS) multi-lingual and multi-provider REST API microservice for generating speech from text."
readme = "README.md"
requires-python = ">=3.12.0, <3.13"
dependencies = [
    "aiosqlite>=0.22.1",
    "argon2-cffi>=25.1.0",
    "asyncpg>=0.31.0",
    "bitsandbytes>=0.49.1",
    "fastapi>=0.128.0",
    "huggingface-hub>=0.36.0",
    "hypercorn>=0.18.0",
    "passlib>=1.7.4",
    "pydantic-settings>=2.12.0",
    "qwen-tts>=0.0.4",
    "safetensors>=0.7.0",
    "soundfile>=0.13.1",
    "sqlmodel>=0.0.31",
    "tomli-w>=1.2.0",
    "torch==2.9",
    "typer>=0.21.1",
    "uuid-utils>=0.14.0",
]

[project.optional-dependencies]
test = [
    "openai>=1.59.7",
    "pytest>=8.3.4",
]
runpod = ["runpod>=1.7.0"]
cuda = ["flash-attn>=2.8.3"]
nvfp4 = [
    "nvidia-cutlass",
    "fp-quant>=0.3.2",
]

[project.scripts]
celestial-tts = "main:cli_app"
celestial-tts-create-token = "create_token:app"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
package = true

[tool.uv.extra-build-dependencies]
flash-attn = ["torch"]

[tool.uv.sources.flash-attn]
url = "https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.7.16/flash_attn-2.6.3+cu128torch2.9-cp312-cp312-linux_x86_64.whl"

[tool.uv.sources.nvidia-cutlass]
git = "https://github.com/NVIDIA/cutlass"
